!pip install opencv-python-headless tensorflow gradio

import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet import preprocess_input

# Load the pre-trained model
model = MobileNetV2(weights='imagenet')

def preprocess_frame(frame):
    img = cv2.resize(frame, (224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    return img_array

def detect_violence(frame):
    preprocessed_frame = preprocess_frame(frame)
    predictions = model.predict(preprocessed_frame)
    # Dummy check for violence; replace with your actual logic
    return np.argmax(predictions) == 0  # Change based on your model's output

import gradio as gr

def process_video(video_path):
    cap = cv2.VideoCapture(video_path)
    frames = []
    results = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if detect_violence(frame):
            results.append("Violence detected!")
        else:
            results.append("No violence detected.")
        frames.append(frame)

    cap.release()
    return results

iface = gr.Interface(fn=process_video, inputs="video", outputs="text")
iface.launch(share=True)
